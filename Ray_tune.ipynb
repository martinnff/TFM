{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organizational-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from os.path import exists\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import scipy.sparse as scpy\n",
    "from torch.nn import Linear\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.data.data as Batch\n",
    "import torch.utils.data as data_utils\n",
    "import torch_geometric.transforms as T\n",
    "from torch.nn.init import xavier_uniform\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch_geometric.datasets as datasets\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch_geometric.transforms as transforms\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
    "from torch_geometric.nn import  GATv2Conv, GraphNorm,  SAGEConv, global_mean_pool, global_max_pool\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sharp-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sp(path,seed=1,split=0.9,parcela=0):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    parcelas = os.listdir(path)\n",
    "    n_sample = round(len(parcelas)*split)\n",
    "    train_ind = np.random.choice(np.linspace(1,len(parcelas),len(parcelas)),n_sample,replace=False).astype(int)\n",
    "    test_ind = np.delete(np.linspace(1,len(parcelas),len(parcelas)),train_ind-1).astype(int)\n",
    "    test_graphs = []\n",
    "    train_graphs = []\n",
    "    \n",
    "    parcela = parcela \n",
    "    for itrain in train_ind:\n",
    "        filename = f\"{path}/parcela{itrain}\"\n",
    "        archivos = os.listdir(filename)\n",
    "        ngrafos=int(len(archivos)/4)\n",
    "        parcela+=1\n",
    "        for i in range(ngrafos):\n",
    "            i+=1\n",
    "            edges = pd.read_csv(f\"{filename}/el{i}.csv\").iloc[:,1:]\n",
    "            attributes = pd.read_csv(f\"{filename}/z{i}.csv\").iloc[:,1]\n",
    "            label = pd.read_csv(f\"{filename}/y{i}.csv\").iloc[:,1]\n",
    "            weights = pd.read_csv(f\"{filename}/ea{i}.csv\").iloc[:,1]\n",
    "            weights = torch.tensor(weights.to_numpy(),dtype=torch.float)\n",
    "            edge_idx = torch.tensor(edges.to_numpy().transpose(), dtype=torch.long)\n",
    "            edge_idx -= 1\n",
    "            attrs = torch.tensor(attributes.to_numpy(), dtype=torch.float)\n",
    "            np_lab = label.to_numpy()\n",
    "            y = torch.tensor(np_lab, dtype=torch.long)-1\n",
    "            y = y[0]\n",
    "            graph = Data(x=attrs, edge_index=edge_idx,  y=y, edge_attr = weights,parcela=parcela)\n",
    "            train_graphs.append(graph)     \n",
    "    for itest in test_ind:\n",
    "        filename = f\"{path}/parcela{itest}\"\n",
    "        archivos = os.listdir(filename)\n",
    "        ngrafos=int(len(archivos)/4)\n",
    "        parcela+=1\n",
    "        for i in range(ngrafos):\n",
    "            i+=1\n",
    "            edges = pd.read_csv(f\"{filename}/el{i}.csv\").iloc[:,1:]\n",
    "            attributes = pd.read_csv(f\"{filename}/z{i}.csv\").iloc[:,1]\n",
    "            label = pd.read_csv(f\"{filename}/y{i}.csv\").iloc[:,1]\n",
    "            weights = pd.read_csv(f\"{filename}/ea{i}.csv\").iloc[:,1]\n",
    "            weights = torch.tensor(weights.to_numpy(),dtype=torch.float)\n",
    "            edge_idx = torch.tensor(edges.to_numpy().transpose(), dtype=torch.long)\n",
    "            edge_idx -= 1\n",
    "            attrs = torch.tensor(attributes.to_numpy(), dtype=torch.float)\n",
    "            np_lab = label.to_numpy()\n",
    "            y = torch.tensor(np_lab, dtype=torch.long)-1\n",
    "            y = y[0]\n",
    "            graph = Data(x=attrs, edge_index=edge_idx,  y=y, edge_attr = weights,parcela=parcela)\n",
    "            test_graphs.append(graph)\n",
    "    return [test_graphs,train_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valid-president",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3219/2925325504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatos1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./datos/grafos/train/sp1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparcela\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdatos2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./datos/grafos/train/sp2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparcela\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdatos3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./datos/grafos/train/sp3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparcela\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3219/3044019595.py\u001b[0m in \u001b[0;36msplit_sp\u001b[0;34m(path, seed, split, parcela)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{filename}/el{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{filename}/z{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{filename}/y{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{filename}/ea{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2034\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2036\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2037\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/local1/lib/python3.8/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datos1 = split_sp(path='./datos/grafos/train/sp1',parcela=0)\n",
    "parcela=(len(datos1[0])+len(datos1[1]))\n",
    "datos2 = split_sp(path='./datos/grafos/train/sp2',parcela=parcela)\n",
    "parcela=parcela+(len(datos2[0])+len(datos2[1]))\n",
    "datos3 = split_sp(path='./datos/grafos/train/sp3',parcela=parcela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nasty-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "test.extend(datos1[0])\n",
    "test.extend(datos2[0])\n",
    "test.extend(datos3[0])\n",
    "\n",
    "train = []\n",
    "train.extend(datos1[1])\n",
    "train.extend(datos2[1])\n",
    "train.extend(datos3[1])\n",
    "\n",
    "with open(\"./datos/train_graphs1_90.pkl\",'wb') as f:\n",
    "    pickle.dump(train,f)\n",
    "with open(\"./datos/test_graphs1_90.pkl\",'wb') as f:\n",
    "    pickle.dump(test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optical-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_list = []\n",
    "        with open(path,'rb') as f:\n",
    "            self.data_list.extend(pickle.load(f))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphDataset(\"./datos/train_graphs1_90.pkl\")\n",
    "test_dataset = GraphDataset(\"./datos/test_graphs1_90.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quantitative-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# funcion para inicializar pesos de la red\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "dp=0.2\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hid = 64, \n",
    "                 in_head = 16, \n",
    "                 out_features = 4,\n",
    "                 s_fc1 = 2048,\n",
    "                 s_fc2 = 1024):\n",
    "        super(GAT, self).__init__()\n",
    "        \n",
    "        self.hid = hid\n",
    "        self.in_head = in_head\n",
    "        self.in_features = 1\n",
    "        self.out_features = out_features\n",
    "        self.s_fc1 = s_fc1\n",
    "        self.s_fc2 = s_fc2\n",
    "        \n",
    "        self.conv1 =  GATv2Conv(self.in_features, self.out_features,edge_dim=1,heads=self.in_head,concat=True)\n",
    "        self.conv2 =  SAGEConv(self.out_features*self.in_head, self.hid,normalize=False)\n",
    "        self.norm1=GraphNorm(self.out_features*self.in_head)\n",
    "        self.fc1 = nn.Linear(self.hid*2,self.s_fc1)\n",
    "        self.fc2 = nn.Linear(self.s_fc1,self.s_fc2)\n",
    "        self.fc3 = nn.Linear(self.s_fc2,3)\n",
    "        self.conv1.apply(init_weights)\n",
    "        self.conv2.apply(init_weights)\n",
    "        self.fc1.apply(init_weights)\n",
    "        self.fc2.apply(init_weights)\n",
    "        self.fc3.apply(init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        edge_attr = torch.unsqueeze(edge_attr,1)\n",
    "        x = torch.unsqueeze(x,-1)\n",
    "        \n",
    "        x = self.conv1(x,edge_index,edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm1(x,batch)\n",
    "        x = F.dropout(x, p=dp, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=dp, training=self.training)\n",
    "        \n",
    "        x1 = global_max_pool(x,batch)\n",
    "        x2 = global_mean_pool(x,batch)\n",
    "        x = torch.cat((x1,x2),1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, p=dp, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=dp, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "talented-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"hid\": tune.choice([4, 8, 16,32, 64,88,128]),\n",
    "    \"in_head\": tune.choice([2, 4, 8, 16,20, 24]),\n",
    "    \"out_features\": tune.choice([2, 4, 6, 8,12]),\n",
    "    \"s_fc1\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "    \"s_fc2\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"wd\": tune.loguniform(5e-4, 1e-6)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hungarian-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graphs(config):\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "            \n",
    "    model = GAT(config['hid'],\n",
    "            config['in_head'],\n",
    "            config['out_features'],\n",
    "            config['s_fc1'],\n",
    "            config['s_fc2'])\n",
    "    \n",
    "    model.to(device)\n",
    "    print(model.train())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['wd'])\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss(torch.tensor([1.1,1.05,1.0]).to(device))\n",
    "\n",
    "\n",
    "    trainset = GraphDataset(\"/home/martin/Master/TFM/grafitos/datos/train_graphs1_90.pkl\")\n",
    "    testset = GraphDataset(\"/home/martin/Master/TFM/grafitos/datos/test_graphs1_90.pkl\")\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        drop_last=True)\n",
    "    \n",
    "    valloader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=int(200),\n",
    "        shuffle=True,\n",
    "        drop_last=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(3):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        lss=0\n",
    "        count=0\n",
    "        for i, data in enumerate(trainloader):\n",
    "\n",
    "            batch=data.to(device)\n",
    "            out = model(batch)\n",
    "            loss = criterion(out, batch.y)\n",
    "            running_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            if(i!=0 and i%5==0):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),2)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            count+=1\n",
    "            \n",
    "\n",
    "        running_loss/=count\n",
    "        epoch_steps += 1\n",
    "    \n",
    "\n",
    "        print('[Epoch %4d/%4d] Loss: % 2.2e' % (epoch + 1, 50, running_loss))\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader):\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                data = data.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += data.y.size(0)\n",
    "                correct += (predicted == data.y).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, data.y)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "        print('[Epoch %4d/%4d] Test Loss: % 2.2e' % (epoch + 1, 50, val_loss / val_steps))\n",
    "        print('[Epoch %4d/%4d] Test Accuracy: % 2.2e' % (epoch + 1, 50, correct / total))\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "diagnostic-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATv2Conv(1, 4, heads=16)\n",
      "  (conv2): SAGEConv(64, 64)\n",
      "  (norm1): GraphNorm(64)\n",
      "  (fc1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=3, bias=True)\n",
      ")\n",
      "[Epoch    1/  50] Loss:  1.03e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 17:48:16,482\tWARNING session.py:32 -- Session not detected. You should not be calling `report` outside `tune.run` or while using the class API. \n",
      "2022-05-11 17:48:16,483\tWARNING session.py:38 --   File \"/home/martin/miniconda3/envs/local1/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/martin/miniconda3/envs/local1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_6031/408887437.py\", line 11, in <module>\n",
      "    a=train_graphs(config=config)\n",
      "  File \"/tmp/ipykernel_6031/671849569.py\", line 88, in train_graphs\n",
      "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch    1/  50] Test Loss:  9.41e-01\n",
      "[Epoch    1/  50] Test Accuracy:  4.97e-01\n",
      "[Epoch    2/  50] Loss:  9.14e-01\n",
      "[Epoch    2/  50] Test Loss:  8.78e-01\n",
      "[Epoch    2/  50] Test Accuracy:  5.70e-01\n",
      "[Epoch    3/  50] Loss:  8.74e-01\n",
      "[Epoch    3/  50] Test Loss:  8.55e-01\n",
      "[Epoch    3/  50] Test Accuracy:  5.86e-01\n",
      "[Epoch    4/  50] Loss:  8.53e-01\n",
      "[Epoch    4/  50] Test Loss:  8.40e-01\n",
      "[Epoch    4/  50] Test Accuracy:  5.94e-01\n",
      "[Epoch    5/  50] Loss:  8.39e-01\n",
      "[Epoch    5/  50] Test Loss:  8.53e-01\n",
      "[Epoch    5/  50] Test Accuracy:  5.85e-01\n",
      "[Epoch    6/  50] Loss:  8.29e-01\n",
      "[Epoch    6/  50] Test Loss:  8.09e-01\n",
      "[Epoch    6/  50] Test Accuracy:  6.19e-01\n",
      "[Epoch    7/  50] Loss:  8.24e-01\n",
      "[Epoch    7/  50] Test Loss:  8.05e-01\n",
      "[Epoch    7/  50] Test Accuracy:  6.20e-01\n",
      "[Epoch    8/  50] Loss:  8.14e-01\n",
      "[Epoch    8/  50] Test Loss:  8.09e-01\n",
      "[Epoch    8/  50] Test Accuracy:  6.16e-01\n",
      "[Epoch    9/  50] Loss:  8.09e-01\n",
      "[Epoch    9/  50] Test Loss:  8.08e-01\n",
      "[Epoch    9/  50] Test Accuracy:  6.13e-01\n",
      "[Epoch   10/  50] Loss:  8.04e-01\n",
      "[Epoch   10/  50] Test Loss:  8.38e-01\n",
      "[Epoch   10/  50] Test Accuracy:  5.94e-01\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"hid\": 64,\n",
    "    \"in_head\":16,\n",
    "    \"out_features\" : 4,\n",
    "    \"s_fc1\":  2048,\n",
    "    \"s_fc2\": 1024,\n",
    "    \"lr\":0.0001,\n",
    "    \"wd\":5e-5,\n",
    "    'batch_size': 80\n",
    "}\n",
    "a=train_graphs(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-bargain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, device=\"cpu\"):\n",
    "\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        test_dataset, batch_size=4, shuffle=False, drop_last=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            data.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == data.y).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "closed-chile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:05:23,939\tINFO trial_runner.py:803 -- starting train_graphs_2a3b0_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:24 (running for 00:00:00.19)\n",
      "Memory usage on this node: 10.6/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m GAT(\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (conv1): GATv2Conv(1, 8, heads=8)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (conv2): SAGEConv(64, 8)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (norm1): GraphNorm(64)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (fc1): Linear(in_features=16, out_features=512, bias=True)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m   (fc3): Linear(in_features=256, out_features=3, bias=True)\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m )\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:31 (running for 00:00:07.22)\n",
      "Memory usage on this node: 11.1/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:36 (running for 00:00:12.22)\n",
      "Memory usage on this node: 11.3/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:41 (running for 00:00:17.22)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:46 (running for 00:00:22.23)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    1/  50] Loss:  1.11e+00\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:51 (running for 00:00:27.23)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+\n",
      "\n",
      "\n",
      "Result for train_graphs_2a3b0_00000:\n",
      "  accuracy: 0.43274193548387097\n",
      "  date: 2022-05-11_18-05-52\n",
      "  done: false\n",
      "  experiment_id: bfcafcaac0e749cf901b7a52757269f4\n",
      "  hostname: martin-Prestige-14-A10SC\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0721577175201908\n",
      "  node_ip: 172.23.73.92\n",
      "  pid: 10961\n",
      "  time_since_restore: 26.040812015533447\n",
      "  time_this_iter_s: 26.040812015533447\n",
      "  time_total_s: 26.040812015533447\n",
      "  timestamp: 1652285152\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2a3b0_00000\n",
      "  warmup_time: 0.0022125244140625\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    1/  50] Test Loss:  1.07e+00\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    1/  50] Test Accuracy:  4.33e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-05-11 18:05:57 (running for 00:00:33.27)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: -1.0721577175201908\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |    loss |   accuracy |   training_iteration |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 | 1.07216 |   0.432742 |                    1 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:06:02 (running for 00:00:38.27)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: -1.0721577175201908\n",
      "Resources requested: 4.0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "| Trial name               | status   | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |    loss |   accuracy |   training_iteration |\n",
      "|--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------|\n",
      "| train_graphs_2a3b0_00000 | RUNNING  | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 | 1.07216 |   0.432742 |                    1 |\n",
      "+--------------------------+----------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    2/  50] Loss:  1.08e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:06:03,486\tINFO tune.py:701 -- Total run time: 39.69 seconds (39.55 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_graphs_2a3b0_00000:\n",
      "  accuracy: 0.40774193548387094\n",
      "  date: 2022-05-11_18-06-03\n",
      "  done: true\n",
      "  experiment_id: bfcafcaac0e749cf901b7a52757269f4\n",
      "  hostname: martin-Prestige-14-A10SC\n",
      "  iterations_since_restore: 2\n",
      "  loss: 1.0607271655913322\n",
      "  node_ip: 172.23.73.92\n",
      "  pid: 10961\n",
      "  time_since_restore: 37.30875873565674\n",
      "  time_this_iter_s: 11.267946720123291\n",
      "  time_total_s: 37.30875873565674\n",
      "  timestamp: 1652285163\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 2a3b0_00000\n",
      "  warmup_time: 0.0022125244140625\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-05-11 18:06:03 (running for 00:00:39.57)\n",
      "Memory usage on this node: 11.5/15.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 2.000: -1.0607271655913322 | Iter 1.000: -1.0721577175201908\n",
      "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/7.55 GiB heap, 0.0/3.77 GiB objects (0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/martin/ray_results/train_graphs_2022-05-11_18-05-23\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+--------------------------+------------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "| Trial name               | status     | loc                |   hid |   in_head |   out_features |   s_fc1 |   s_fc2 |         lr |          wd |    loss |   accuracy |   training_iteration |\n",
      "|--------------------------+------------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------|\n",
      "| train_graphs_2a3b0_00000 | TERMINATED | 172.23.73.92:10961 |     8 |         8 |              8 |     512 |     256 | 3.1047e-05 | 0.000104569 | 1.06073 |   0.407742 |                    2 |\n",
      "+--------------------------+------------+--------------------+-------+-----------+----------------+---------+---------+------------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    2/  50] Test Loss:  1.06e+00\n",
      "\u001b[2m\u001b[36m(train_graphs pid=10961)\u001b[0m [Epoch    2/  50] Test Accuracy:  4.08e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    \"hid\": tune.choice([4, 8, 16,32, 64,88,128]),\n",
    "    \"in_head\": tune.choice([2, 4, 8, 16,20, 24]),\n",
    "    \"out_features\": tune.choice([2, 4, 6, 8,12,16]),\n",
    "    \"s_fc1\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "    \"s_fc2\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"wd\": tune.loguniform(5e-4, 1e-6),\n",
    "    \"batch_size\": tune.uniform(20,1000)\n",
    "}\n",
    "\n",
    "gpus_per_trial = 0\n",
    "result = tune.run(train_graphs,\n",
    "    resources_per_trial={\"cpu\":4, \"gpu\": gpus_per_trial},\n",
    "    config=config,\n",
    "    num_samples=1,\n",
    "    scheduler=ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=2,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2),\n",
    "    progress_reporter=CLIReporter(\n",
    "        parameter_columns=[\"hid\",\"in_head\",\"out_features\",\"s_fc1\",\"s_fc2\",\"lr\",\"wd\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "creative-vintage",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6031/2443047140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=50, gpus_per_trial=1):\n",
    "    #data_dir = os.path.abspath(\"./data\")\n",
    "    #load_data(data_dir)\n",
    "    config = {\n",
    "        \"hid\": tune.choice([4, 8, 16,32, 64,88,128]),\n",
    "        \"in_head\": tune.choice([2, 4, 8, 16,20, 24]),\n",
    "        \"in_features\": 1,\n",
    "        \"out_features\": tune.choice([2, 4, 6, 8,12,16,32]),\n",
    "        \"s_fc1\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "        \"s_fc2\": tune.choice([256, 512, 1024, 2048,3096]),\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "        \"wd\": tune.loguniform(5e-4, 1e-6)\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"hid\",\"in_head\",\"in_features\",\"out_features\",\"s_fc1\",\"s_fc2\",\"lr\",\"wd\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_graphs),\n",
    "        resources_per_trial={\"cpu\": 4, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = model(best_trial.config[\"hid\"],\n",
    "                               best_trial.config[\"in_head\"],\n",
    "                               best_trial.config[\"in_features\"],\n",
    "                               best_trial.config[\"out_features\"],\n",
    "                               best_trial.config[\"s_fc1\"],\n",
    "                               best_trial.config[\"s_fc2\"],\n",
    "                               best_trial.config[\"lr\"],\n",
    "                               best_trial.config[\"wd\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=10, max_num_epochs=2, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local1",
   "language": "python",
   "name": "local1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
